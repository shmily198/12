{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "# from sklearn.xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#读取文件\n",
    "data = pd.read_csv('gcc.csv')\n",
    "# data1 = data['emd_lable2']\n",
    "X3 = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "emd_lable2\n",
       "0.0    21957\n",
       "1.0    21957\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X3.groupby(X3['emd_lable2']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>pax_tax</th>\n",
       "      <th>pax_fcny</th>\n",
       "      <th>avg_dist_cnt_y3</th>\n",
       "      <th>seg_flight</th>\n",
       "      <th>tkt_3y_amt</th>\n",
       "      <th>dist_cnt_y3</th>\n",
       "      <th>seat_walkway_cnt_y3</th>\n",
       "      <th>emd_lable2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000809</td>\n",
       "      <td>0.000596</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.001236</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000344</td>\n",
       "      <td>0.000392</td>\n",
       "      <td>0.347172</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.001236</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.000417</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.001236</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000629</td>\n",
       "      <td>0.000319</td>\n",
       "      <td>0.754508</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.007383</td>\n",
       "      <td>0.030705</td>\n",
       "      <td>0.006993</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000393</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.007466</td>\n",
       "      <td>0.040664</td>\n",
       "      <td>0.017483</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43909</th>\n",
       "      <td>43909</td>\n",
       "      <td>0.000415</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>0.411954</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.001236</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43910</th>\n",
       "      <td>43910</td>\n",
       "      <td>0.000628</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>0.700813</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.008580</td>\n",
       "      <td>0.057040</td>\n",
       "      <td>0.006993</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43911</th>\n",
       "      <td>43911</td>\n",
       "      <td>0.000365</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.001236</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43912</th>\n",
       "      <td>43912</td>\n",
       "      <td>0.000629</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.008580</td>\n",
       "      <td>0.075018</td>\n",
       "      <td>0.006993</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43913</th>\n",
       "      <td>43913</td>\n",
       "      <td>0.000317</td>\n",
       "      <td>0.000315</td>\n",
       "      <td>0.821526</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.001236</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43914 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0   pax_tax  pax_fcny  avg_dist_cnt_y3  seg_flight  \\\n",
       "0               0  0.000809  0.000596         0.000000      0.3750   \n",
       "1               1  0.000344  0.000392         0.347172      0.3750   \n",
       "2               2  0.000417  0.000057         0.000000      0.5625   \n",
       "3               3  0.000629  0.000319         0.754508      0.5625   \n",
       "4               4  0.000393  0.000158         0.000000      0.6250   \n",
       "...           ...       ...       ...              ...         ...   \n",
       "43909       43909  0.000415  0.000098         0.411954      0.6250   \n",
       "43910       43910  0.000628  0.000166         0.700813      0.6250   \n",
       "43911       43911  0.000365  0.000040         0.000000      0.5000   \n",
       "43912       43912  0.000629  0.000178         0.000000      0.3750   \n",
       "43913       43913  0.000317  0.000315         0.821526      0.3750   \n",
       "\n",
       "       tkt_3y_amt  dist_cnt_y3  seat_walkway_cnt_y3  emd_lable2  \n",
       "0        0.001236     0.000000             0.000000         0.0  \n",
       "1        0.001236     0.000000             0.000000         0.0  \n",
       "2        0.001236     0.000000             0.000000         0.0  \n",
       "3        0.007383     0.030705             0.006993         0.0  \n",
       "4        0.007466     0.040664             0.017483         1.0  \n",
       "...           ...          ...                  ...         ...  \n",
       "43909    0.001236     0.000000             0.000000         1.0  \n",
       "43910    0.008580     0.057040             0.006993         1.0  \n",
       "43911    0.001236     0.000000             0.000000         1.0  \n",
       "43912    0.008580     0.075018             0.006993         1.0  \n",
       "43913    0.001236     0.000000             0.000000         1.0  \n",
       "\n",
       "[43914 rows x 9 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X3.drop(['pax_name'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mdl_mcv</th>\n",
       "      <th>dist_all_cnt_y3</th>\n",
       "      <th>dist_all_cnt_y2</th>\n",
       "      <th>dist_i_cnt_y3</th>\n",
       "      <th>dist_i_cnt_y2</th>\n",
       "      <th>avg_dist_cnt_y3</th>\n",
       "      <th>dist_cnt_y3</th>\n",
       "      <th>pref_month_y3_1</th>\n",
       "      <th>emd_lable2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.347172</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.030705</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030705</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.754508</td>\n",
       "      <td>0.030705</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.040664</td>\n",
       "      <td>0.053711</td>\n",
       "      <td>0.040664</td>\n",
       "      <td>0.053419</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.040664</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23427</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23428</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23429</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23430</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23431</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23432 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        mdl_mcv  dist_all_cnt_y3  dist_all_cnt_y2  dist_i_cnt_y3  \\\n",
       "0      0.000000         0.000000         0.000000       0.000000   \n",
       "1      0.166667         0.000000         0.000000       0.000000   \n",
       "2      0.000000         0.000000         0.000000       0.000000   \n",
       "3      0.166667         0.030705         0.000000       0.030705   \n",
       "4      0.000000         0.040664         0.053711       0.040664   \n",
       "...         ...              ...              ...            ...   \n",
       "23427  0.000000         0.000000         0.000000       0.000000   \n",
       "23428  0.000000         0.000000         0.000000       0.000000   \n",
       "23429  0.000000         0.000000         0.000000       0.000000   \n",
       "23430  0.000000         0.000000         0.000000       0.000000   \n",
       "23431  0.000000         0.000000         0.000000       0.000000   \n",
       "\n",
       "       dist_i_cnt_y2  avg_dist_cnt_y3  dist_cnt_y3  pref_month_y3_1  \\\n",
       "0           0.000000         0.000000     0.000000         0.000000   \n",
       "1           0.000000         0.347172     0.000000         0.166667   \n",
       "2           0.000000         0.000000     0.000000         0.000000   \n",
       "3           0.000000         0.754508     0.030705         0.625000   \n",
       "4           0.053419         0.000000     0.040664         0.000000   \n",
       "...              ...              ...          ...              ...   \n",
       "23427       0.000000         0.000000     0.000000         0.000000   \n",
       "23428       0.000000         0.000000     0.000000         0.000000   \n",
       "23429       0.000000         0.000000     0.000000         0.000000   \n",
       "23430       0.000000         0.000000     0.000000         0.000000   \n",
       "23431       0.000000         0.000000     0.000000         0.000000   \n",
       "\n",
       "       emd_lable2  \n",
       "0               0  \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  \n",
       "4               1  \n",
       "...           ...  \n",
       "23427           0  \n",
       "23428           0  \n",
       "23429           0  \n",
       "23430           0  \n",
       "23431           0  \n",
       "\n",
       "[23432 rows x 9 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# 训练集矩阵\n",
    "# array = X3.values\n",
    "\n",
    "Y = X3.pop('emd_lable2')\n",
    "X = X3.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+00, 8.09123633e-04, 5.95642896e-04, ...,\n",
       "        1.23579143e-03, 0.00000000e+00, 0.00000000e+00],\n",
       "       [1.00000000e+00, 3.44455213e-04, 3.91623479e-04, ...,\n",
       "        1.23579143e-03, 0.00000000e+00, 0.00000000e+00],\n",
       "       [2.00000000e+00, 4.17153537e-04, 5.69847337e-05, ...,\n",
       "        1.23579143e-03, 0.00000000e+00, 0.00000000e+00],\n",
       "       ...,\n",
       "       [4.39110000e+04, 3.64709954e-04, 3.98658631e-05, ...,\n",
       "        1.23579143e-03, 0.00000000e+00, 0.00000000e+00],\n",
       "       [4.39120000e+04, 6.29281462e-04, 1.78223859e-04, ...,\n",
       "        8.58004898e-03, 7.50180618e-02, 6.99300699e-03],\n",
       "       [4.39130000e+04, 3.17333518e-04, 3.15409329e-04, ...,\n",
       "        1.23579143e-03, 0.00000000e+00, 0.00000000e+00]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0.0\n",
       "1        0.0\n",
       "2        0.0\n",
       "3        0.0\n",
       "4        1.0\n",
       "        ... \n",
       "43909    1.0\n",
       "43910    1.0\n",
       "43911    1.0\n",
       "43912    1.0\n",
       "43913    1.0\n",
       "Name: emd_lable2, Length: 43914, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:293: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "folds = 10\n",
    "seed = 7\n",
    "kfold = KFold(n_splits=folds,random_state=seed)\n",
    "models = {}\n",
    "models['LR'] = LogisticRegression()\n",
    "models['LDA'] = LinearDiscriminantAnalysis()\n",
    "models['KNN'] = KNeighborsClassifier()\n",
    "models['CART'] = DecisionTreeClassifier()\n",
    "models['SVM'] = SVC()\n",
    "models['NB'] = GaussianNB()\n",
    "models['XGboost'] = XGBClassifier()\n",
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR:0.769(0.362)\n",
      "LDA:0.930(0.078)\n",
      "KNN:0.950(0.054)\n",
      "CART:0.923(0.067)\n",
      "SVM:0.940(0.079)\n",
      "NB:0.887(0.164)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:15:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:15:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:15:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:15:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:15:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:15:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:15:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:15:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:15:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:15:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGboost:0.952(0.050)\n"
     ]
    }
   ],
   "source": [
    "for name in models:\n",
    "    result = cross_val_score(models[name], X , Y, cv=kfold)\n",
    "    results.append(result)\n",
    "    msg = '%s:%.3f(%.3f)'%(name,result.mean(),result.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:214: RuntimeWarning: Glyph 31639 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "G:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:214: RuntimeWarning: Glyph 27861 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "G:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:214: RuntimeWarning: Glyph 27169 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "G:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:214: RuntimeWarning: Glyph 22411 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "G:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:214: RuntimeWarning: Glyph 27604 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "G:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:214: RuntimeWarning: Glyph 36739 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "G:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:183: RuntimeWarning: Glyph 31639 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "G:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:183: RuntimeWarning: Glyph 27861 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "G:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:183: RuntimeWarning: Glyph 27169 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "G:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:183: RuntimeWarning: Glyph 22411 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "G:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:183: RuntimeWarning: Glyph 27604 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "G:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:183: RuntimeWarning: Glyph 36739 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = pyplot.figure()\n",
    "fig.suptitle('算法模型比较')\n",
    "ax = fig.add_subplot(111)\n",
    "pyplot.boxplot(results)\n",
    "ax.set_xticklabels(models.keys())\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
